# Image-Captioning-using-Attention-Mechanism
Created a deep learning model which can explain the contents of an image in the form of speech through caption generation with an attention mechanism on Flickr8K dataset.

Dataset:
Created a deep learning model which can explain the contents of an image in the form of speech through caption generation with an attention mechanism on Flickr8K dataset
Dataset: The dataset is taken from the Kaggle website and it consists of sentence-based image descriptions having a list of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events of the image.

Method:
• Built a custom Encoder - Decoder architecture with Attention Mechanism for image captioning and later used a text to speech converter to provide the output in the form of an audio
• The predicted caption was ranked based on Greedy Search and evaluated using the Bilingual Evaluation Understudy (BLEU) score

